We have presented a task-based programming model and runtime system for accelerator-based clusters.
Experimental results on four benchmarks show that with the new code representation the programmer can realize better performance.
The performance improvement comes from increasing throughput of processing fine-grained tasks on each individual GPU, dynamic load balancing, direct communication among GPUs and/or hiding communication overheads.
Our solution offers a simple interface so the programmer can study these benefits without the needs of redesigning the algorithm and aggressively restructuring the source code as the system architecture evolves.
We deem that our paper not only has impact on application development, but it can also initiate further research on HPC libraries such as developing and tuning cuSPARSE routines for running on the same GPUs. 
